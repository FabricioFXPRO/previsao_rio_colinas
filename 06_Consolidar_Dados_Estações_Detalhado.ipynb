{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos encontrados: ['dados_estacao_detalhada_86520100-2018.csv', 'dados_estacao_detalhada_86520100-2019.csv', 'dados_estacao_detalhada_86520100-2020.csv', 'dados_estacao_detalhada_86520100-2021.csv', 'dados_estacao_detalhada_86520100-2022.csv', 'dados_estacao_detalhada_86520100-2023.csv', 'dados_estacao_detalhada_86520100-2024.csv']\n",
      "Erro ao ler o arquivo dados_estacao_detalhada_86520100-2018.csv: No columns to parse from file\n",
      "Erro ao ler o arquivo dados_estacao_detalhada_86520100-2019.csv: No columns to parse from file\n",
      "Erro ao ler o arquivo dados_estacao_detalhada_86520100-2020.csv: No columns to parse from file\n",
      "Arquivo dados_estacao_detalhada_86520100-2021.csv lido com sucesso.\n",
      "Arquivo dados_estacao_detalhada_86520100-2022.csv lido com sucesso.\n",
      "Arquivo dados_estacao_detalhada_86520100-2023.csv lido com sucesso.\n",
      "Arquivo dados_estacao_detalhada_86520100-2024.csv lido com sucesso.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# 1. Definir o código da estação\n",
    "codigo_estacao = '86520100'\n",
    "\n",
    "# 2. Listar todos os arquivos CSV correspondentes à estação\n",
    "# Ajuste o caminho se os arquivos estiverem em um diretório diferente\n",
    "file_pattern = f'dados_estacao_detalhada_{codigo_estacao}-*.csv'\n",
    "file_list = glob.glob(file_pattern)\n",
    "\n",
    "# Verificar se arquivos foram encontrados\n",
    "if not file_list:\n",
    "    print(\"Nenhum arquivo encontrado para o padrão especificado.\")\n",
    "else:\n",
    "    print(f\"Arquivos encontrados: {file_list}\")\n",
    "\n",
    "# 3. Inicializar uma lista para armazenar os DataFrames\n",
    "df_list = []\n",
    "\n",
    "# 4. Ler cada arquivo CSV e adicionar à lista\n",
    "for file in file_list:\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "        df_list.append(df)\n",
    "        print(f\"Arquivo {file} lido com sucesso.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao ler o arquivo {file}: {e}\")\n",
    "\n",
    "# 5. Concatenar todos os DataFrames em um único DataFrame\n",
    "df_all = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# 6. Converter 'Data_Hora_Medicao' para datetime\n",
    "df_all['Data_Hora_Medicao'] = pd.to_datetime(df_all['Data_Hora_Medicao'], errors='coerce')\n",
    "\n",
    "# Remover linhas com datas inválidas (se houver)\n",
    "df_all = df_all.dropna(subset=['Data_Hora_Medicao'])\n",
    "\n",
    "# 7. Ordenar o DataFrame por 'Data_Hora_Medicao'\n",
    "df_all = df_all.sort_values('Data_Hora_Medicao')\n",
    "\n",
    "# 8. Definir 'Data_Hora_Medicao' como índice\n",
    "df_all.set_index('Data_Hora_Medicao', inplace=True)\n",
    "\n",
    "# 9. Reindexar o DataFrame para ter um índice temporal contínuo\n",
    "# Definir o início e fim com base nas datas existentes\n",
    "start_date = df_all.index.min()\n",
    "end_date = df_all.index.max()\n",
    "\n",
    "# Criar um novo índice com frequência horária\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='H')\n",
    "\n",
    "# Reindexar o DataFrame\n",
    "#df_all = df_all.reindex(date_range)\n",
    "\n",
    "# Opcional: Renomear o índice para 'Data_Hora_Medicao'\n",
    "df_all.index.name = 'Data_Hora_Medicao'\n",
    "\n",
    "# 10. Resetar o índice se preferir trabalhar com ele como coluna\n",
    "# df_all.reset_index(inplace=True)\n",
    "\n",
    "# Exclui todas as linhas com data superior a 2024-31-08\n",
    "df_all = df_all[df_all.index <= '2024-09-01']\n",
    "\n",
    "# 12. Tratar dados ausentes (opcional)\n",
    "# Você pode optar por preencher valores ausentes usando interpolação ou outros métodos\n",
    "# Por exemplo, usando interpolação linear:\n",
    "# df_all.interpolate(method='linear', inplace=True)\n",
    "# salva o dataframe consolidado em um arquivo CSV\n",
    "output_file = f'dados_estacao_detalhada_{codigo_estacao}_consolidado_ALL.csv'\n",
    "df_all.to_csv(output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
